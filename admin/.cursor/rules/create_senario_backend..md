
ğŸ“Œ Ø¯Ø±Ú© Ø¯Ø±Ø³Øª Ø§Ø² Ø³Ù†Ø§Ø±ÛŒÙˆ:
âœ… Ú†ÛŒØ²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù…ÙˆÙ†Ù†:

âœ… Ù‡Ø± ØªÙˆÙ„ÛŒØ¯ (Chat, Content, Image, Audio) ViewSet Ùˆ API Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¯Ø§Ø±Ù†
âœ… Ø¬Ø¯ÙˆÙ„ AIModel Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø´Ù‡
âœ… Ù‡Ø± capability (chat, image, ...) ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ø¯Ø§Ø±Ù‡
âœ… Ø¯Ø± Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ù…ÛŒØªÙˆÙ†Ù† Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†Ù†

âŒ Ù…Ø´Ú©Ù„ ÙØ¹Ù„ÛŒ:
python# Ø§Ù„Ø§Ù† Ø§ÛŒÙ† Ø§ØªÙØ§Ù‚ Ù…ÛŒÙØªÙ‡:
@action(detail=False, methods=['post'], url_path='sync-models')
def sync_models(self, request):
    # Ù…ÛŒØ±Ù‡ 400 Ù…Ø¯Ù„ OpenRouter Ø±Ùˆ Ù…ÛŒØ§Ø±Ù‡
    # Ù‡Ù…Ù‡ Ø±Ùˆ ØªÙˆÛŒ Ø¬Ø¯ÙˆÙ„ AIModel Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ ğŸ˜±
    # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù¾Ø± Ù…ÛŒØ´Ù‡!
âœ… Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¯Ø±Ø³Øª:

Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ real-time Ø§Ø² API Ø¨Ú¯ÛŒØ±ÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB)
ÙˆÙ‚ØªÛŒ Ø§Ø¯Ù…ÛŒÙ† Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯ØŒ ÙÙ‚Ø· Ø§ÙˆÙ† ÛŒÚ©ÛŒ Ø±Ùˆ Ø¯Ø± AIModel Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒÙ…
Ø¨Ø±Ø§ÛŒ Ù‡Ø± provider ÙÙ‚Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± DB Ø¨Ø§Ø´Ù† (Ù†Ù‡ ØµØ¯Ù‡Ø§ Ù…Ø¯Ù„!)


ğŸ¯ Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¨Ù‡ÛŒÙ†Ù‡:
1ï¸âƒ£ Ø­Ø°Ù Sync - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Real-time API
python# âŒ Ù‚Ø¨Ù„: Sync ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§
@action(detail=False, methods=['post'], url_path='sync-models')
def sync_models(self, request):
    models = OpenRouterProvider.get_available_models()  # 400 model
    for model in models:
        AIModel.objects.create(...)  # ğŸ˜± 400 Ø±Ú©ÙˆØ±Ø¯!

# âœ… Ø¨Ø¹Ø¯: ÙÙ‚Ø· Ù„ÛŒØ³Øª Ø¨Ú¯ÛŒØ± (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡)
@action(detail=False, methods=['get'], url_path='available-models')
def available_models(self, request):
    """Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø± Ù¾Ù†Ù„ - Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡"""
    provider_slug = request.query_params.get('provider')
    capability = request.query_params.get('capability')
    
    # Ø¯Ø±ÛŒØ§ÙØª real-time Ø§Ø² API
    models = self._fetch_models_from_api(provider_slug)
    
    # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ capability
    filtered = self._filter_by_capability(models, capability)
    
    # ÙÙ‚Ø· Ø¨Ø±Ú¯Ø±Ø¯ÙˆÙ† - Ø°Ø®ÛŒØ±Ù‡ Ù†Ú©Ù†!
    return APIResponse.success(data=filtered)

2ï¸âƒ£ Ø°Ø®ÛŒØ±Ù‡ ÙÙ‚Ø· Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
python# Backend/src/ai/views/ai_model_management_views.py

class AIModelManagementViewSet(viewsets.ViewSet):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†"""
    
    @action(detail=False, methods=['get'], url_path='browse-models')
    def browse_models(self, request):
        """
        ğŸ“‹ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ available Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨
        Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± DB Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÛŒØ´Ù†!
        
        Query params:
        - provider: openrouter, huggingface, groq
        - capability: chat, image, content, audio
        """
        provider_slug = request.query_params.get('provider')
        capability = request.query_params.get('capability')
        
        if not provider_slug:
            return APIResponse.error(
                message="Provider is required",
                status_code=400
            )
        
        try:
            provider = AIProvider.objects.get(slug=provider_slug, is_active=True)
            api_key = provider.get_shared_api_key()
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø§Ø² API (Ú©Ø´ Ù…ÛŒØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)
            cache_key = f"available_models_{provider_slug}_{capability}"
            models = cache.get(cache_key)
            
            if not models:
                models = self._fetch_from_provider_api(
                    provider_slug, 
                    api_key,
                    capability
                )
                cache.set(cache_key, models, 6 * 60 * 60)  # 6 hours
            
            return APIResponse.success(
                message=f"Found {len(models)} models",
                data={
                    'provider': provider_slug,
                    'capability': capability,
                    'models': models,
                    'total': len(models)
                }
            )
            
        except Exception as e:
            return APIResponse.error(
                message=f"Error fetching models: {str(e)}",
                status_code=500
            )
    
    @action(detail=False, methods=['post'], url_path='select-model')
    def select_model(self, request):
        """
        âœ… Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¯Ø± DB
        ÙÙ‚Ø· Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒØ´Ù‡!
        
        Body:
        {
            "provider": "openrouter",
            "capability": "chat",
            "model_id": "google/gemini-2.0-flash",
            "model_name": "Gemini 2.0 Flash"
        }
        """
        provider_slug = request.data.get('provider')
        capability = request.data.get('capability')
        model_id = request.data.get('model_id')
        model_name = request.data.get('model_name')
        
        try:
            provider = AIProvider.objects.get(slug=provider_slug, is_active=True)
            
            # 1. ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ Ù‡Ù…ÛŒÙ† capability
            AIModel.objects.filter(
                provider=provider,
                capabilities__contains=capability
            ).update(is_active=False)
            
            # 2. Ø§ÛŒØ¬Ø§Ø¯/Ø¢Ù¾Ø¯ÛŒØª Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯
            model, created = AIModel.objects.update_or_create(
                provider=provider,
                model_id=model_id,
                defaults={
                    'name': model_name,
                    'display_name': model_name,
                    'capabilities': [capability],
                    'is_active': True,
                }
            )
            
            # 3. Ú©Ø´ Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†
            AICacheManager.invalidate_models()
            
            return APIResponse.success(
                message=f"Model selected successfully",
                data={
                    'id': model.id,
                    'model_id': model.model_id,
                    'name': model.display_name,
                    'capability': capability,
                    'is_active': model.is_active
                }
            )
            
        except Exception as e:
            return APIResponse.error(
                message=f"Error selecting model: {str(e)}",
                status_code=500
            )
    
    @action(detail=False, methods=['get'], url_path='selected-models')
    def get_selected_models(self, request):
        """
        ğŸ“Œ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ (Ú©Ù‡ Ø¯Ø± DB Ù‡Ø³ØªÙ†)
        """
        provider_slug = request.query_params.get('provider')
        
        queryset = AIModel.objects.filter(
            is_active=True,
            provider__is_active=True
        ).select_related('provider')
        
        if provider_slug:
            queryset = queryset.filter(provider__slug=provider_slug)
        
        serializer = AIModelListSerializer(queryset, many=True)
        
        return APIResponse.success(
            message="Selected models retrieved",
            data=serializer.data
        )
    
    def _fetch_from_provider_api(self, provider_slug: str, api_key: str, 
                                 capability: str = None) -> list:
        """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² API provider"""
        
        if provider_slug == 'openrouter':
            from src.ai.providers.openrouter import OpenRouterProvider
            models = OpenRouterProvider.get_available_models(
                api_key=api_key,
                use_cache=True
            )
            
        elif provider_slug == 'huggingface':
            from src.ai.providers.huggingface import HuggingFaceProvider
            task_map = {
                'chat': 'text-generation',
                'content': 'text-generation',
                'image': 'text-to-image',
                'audio': 'text-to-speech'
            }
            task = task_map.get(capability)
            models = HuggingFaceProvider.get_available_models(
                api_key=api_key,
                task_filter=task,
                use_cache=True
            )
            
        elif provider_slug == 'groq':
            from src.ai.providers.groq import GroqProvider
            models = GroqProvider.get_available_models(
                api_key=api_key,
                use_cache=True
            )
        else:
            return []
        
        # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ capability
        if capability:
            models = [m for m in models if self._model_supports_capability(m, capability)]
        
        return models
    
    def _model_supports_capability(self, model: dict, capability: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø¯Ù„ Ø§Ø² capability Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡"""
        model_id = model.get('id', '').lower()
        
        if capability == 'image':
            return any(kw in model_id for kw in ['dall-e', 'flux', 'stable', 'imagen'])
        elif capability == 'audio':
            return any(kw in model_id for kw in ['tts', 'whisper', 'audio'])
        else:  # chat, content
            return True  # Ø§Ú©Ø«Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§

3ï¸âƒ£ Registry Pattern (Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ)
python# Backend/src/ai/providers/registry.py

class AIProviderRegistry:
    """Auto-discovery providerÙ‡Ø§ - Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ"""
    
    _instance = None
    _providers: Dict[str, Type[BaseProvider]] = {}
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self.auto_discover()
    
    def auto_discover(self):
        """Ú©Ø´Ù Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙ…Ø§Ù… providerÙ‡Ø§"""
        # Import ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§
        from .gemini import GeminiProvider
        from .openai import OpenAIProvider
        from .openrouter import OpenRouterProvider
        from .groq import GroqProvider
        from .huggingface import HuggingFaceProvider
        from .deepseek import DeepSeekProvider
        
        self.register('gemini', GeminiProvider)
        self.register('openai', OpenAIProvider)
        self.register('openrouter', OpenRouterProvider)
        self.register('groq', GroqProvider)
        self.register('huggingface', HuggingFaceProvider)
        self.register('deepseek', DeepSeekProvider)
    
    @classmethod
    def register(cls, name: str, provider_class: Type[BaseProvider]):
        cls._providers[name] = provider_class
    
    @classmethod
    def get(cls, name: str) -> Type[BaseProvider]:
        return cls._providers.get(name)
    
    @classmethod
    def create_instance(cls, name: str, api_key: str, config: dict = None):
        provider_class = cls.get(name)
        if not provider_class:
            raise ValueError(f"Provider '{name}' not found")
        return provider_class(api_key, config)

# Initialize
_registry = AIProviderRegistry()

4ï¸âƒ£ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ViewÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
python# Backend/src/ai/views/chat_views.py (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø§Ø³Ø§Ø³ÛŒ!)

from src.ai.providers.registry import AIProviderRegistry

class AIChatViewSet(viewsets.ViewSet):
    
    @action(detail=False, methods=['post'], url_path='send-message')
    def send_message(self, request):
        # ... permission checks ...
        
        # 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ ÙØ¹Ø§Ù„
        model = AIModel.objects.get_active_model('openrouter', 'chat')
        
        # 2. Ø¯Ø±ÛŒØ§ÙØª API key
        api_key = self._get_api_key(model.provider, request.user)
        
        # 3. Ø§ÛŒØ¬Ø§Ø¯ provider Ø§Ø² Registry (Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ!)
        registry = AIProviderRegistry()
        provider = registry.create_instance(
            name=model.provider.slug,
            api_key=api_key,
            config={'model': model.model_id}
        )
        
        # 4. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² provider
        loop = asyncio.get_event_loop()
        reply = loop.run_until_complete(
            provider.chat(message, conversation_history)
        )
        
        return APIResponse.success(data={'reply': reply})
```

---

## ğŸ“ **Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:**
```
Backend/src/ai/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ai_provider.py          âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ base.py                 âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ registry.py             â­ Ø¬Ø¯ÛŒØ¯ - Auto-discovery
â”‚   â”œâ”€â”€ gemini.py               âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ openai.py               âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ openrouter.py           âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ groq.py                 âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ huggingface.py          âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â””â”€â”€ deepseek.py             âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚
â”œâ”€â”€ views/
â”‚   â”œâ”€â”€ ai_provider_views.py    âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ chat_views.py           âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† (Ø¨Ø§ Registry)
â”‚   â”œâ”€â”€ content_generation_views.py  âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ image_generation_views.py    âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ audio_generation_views.py    âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ ai_model_management_views.py â­ Ø¬Ø¯ÛŒØ¯ - Browse & Select
â”‚   â””â”€â”€ ai_model_sync_views.py  âŒ Ø­Ø°Ù (Ø¯ÛŒÚ¯Ù‡ sync Ù†Ø¯Ø§Ø±ÛŒÙ…!)
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chat_service.py         âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† (Ø¨Ø§ Registry)
â”‚   â”œâ”€â”€ content_generation_service.py  âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â”œâ”€â”€ image_generation_service.py    âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚   â””â”€â”€ audio_generation_service.py    âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ†
â”‚
â””â”€â”€ urls.py                     ğŸ”„ Ø¢Ù¾Ø¯ÛŒØª

ğŸ”„ URLs Ø¬Ø¯ÛŒØ¯:
python# Backend/src/ai/urls.py

router = DefaultRouter()

# â­ Model Management (Ø¬Ø¯ÛŒØ¯)
router.register(r'admin/ai-model-management', 
                AIModelManagementViewSet, 
                basename='ai-model-management')

# âœ… ViewÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ (Ø¨Ø¯