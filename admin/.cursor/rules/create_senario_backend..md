ğŸ“Œ Ø¯Ø±Ú© ØµØ­ÛŒØ­ Ø§Ø² Ø³Ù†Ø§Ø±ÛŒÙˆ:
âœ… Ú†ÛŒØ²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø´Ù‡:

Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² API Ø¨Ø®ÙˆÙ†ÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB)
Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± DB Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø´Ù‡ (ÙÙ‚Ø· ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± capability)
Dynamic - provider Ø¬Ø¯ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø´Ù‡
Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ - Ø§Ø² Registry Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
Ø³Ø±Ø¹Øª - cache Ú©Ù†ÛŒÙ…


ğŸ¯ Ø³Ø§Ø®ØªØ§Ø± ØµØ­ÛŒØ­:
1ï¸âƒ£ Ø¬Ø¯ÙˆÙ„ AIModel (ÙÙ‚Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡)
python# Backend/src/ai/models/ai_provider.py

class AIModel(BaseModel):
    """
    ÙÙ‚Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø¬Ø¯ÙˆÙ„ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´Ù†
    Ù…Ø«Ù„Ø§Ù‹: ÙÙ‚Ø· 5-10 Ø±Ú©ÙˆØ±Ø¯ (ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± capability)
    """
    provider = models.ForeignKey(AIProvider, on_delete=models.CASCADE)
    model_id = models.CharField(max_length=200)  # "google/gemini-2.0-flash"
    display_name = models.CharField(max_length=200)
    capabilities = models.JSONField(default=list)  # ["chat"]
    is_active = models.BooleanField(default=True)
    
    class Meta:
        unique_together = ['provider', 'model_id']
    
    def save(self, *args, **kwargs):
        """ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± provider+capability"""
        if self.is_active:
            for capability in self.capabilities:
                # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
                AIModel.objects.filter(
                    provider=self.provider,
                    capabilities__contains=capability,
                    is_active=True
                ).exclude(pk=self.pk).update(is_active=False)
        
        super().save(*args, **kwargs)

2ï¸âƒ£ Registry Pattern (Auto-discovery)
python# Backend/src/ai/providers/registry.py

from typing import Dict, Type, Optional, List
from .base import BaseProvider

class AIProviderRegistry:
    """
    â­ ØªÙ…Ø§Ù… providerÙ‡Ø§ Ø±Ùˆ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
    â­ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ import Ø¯Ø³ØªÛŒ Ø¯Ø± ViewÙ‡Ø§
    """
    
    _instance = None
    _providers: Dict[str, Type[BaseProvider]] = {}
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self._auto_discover()
    
    def _auto_discover(self):
        """Ú©Ø´Ù Ø®ÙˆØ¯Ú©Ø§Ø± providerÙ‡Ø§"""
        # Ø§ÛŒÙ† import ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒØ´Ù‡
        from .gemini import GeminiProvider
        from .openai import OpenAIProvider
        from .openrouter import OpenRouterProvider
        from .groq import GroqProvider
        from .huggingface import HuggingFaceProvider
        from .deepseek import DeepSeekProvider
        
        # Ø«Ø¨Øª providerÙ‡Ø§
        self._providers = {
            'gemini': GeminiProvider,
            'openai': OpenAIProvider,
            'openrouter': OpenRouterProvider,
            'groq': GroqProvider,
            'huggingface': HuggingFaceProvider,
            'deepseek': DeepSeekProvider,
        }
    
    def get_provider_class(self, slug: str) -> Optional[Type[BaseProvider]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ø§Ø³ provider"""
        return self._providers.get(slug)
    
    def get_all_providers(self) -> Dict[str, Type[BaseProvider]]:
        """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… providerÙ‡Ø§"""
        return self._providers.copy()
    
    def create_instance(self, slug: str, api_key: str, 
                       config: dict = None) -> BaseProvider:
        """Ø§ÛŒØ¬Ø§Ø¯ instance Ø§Ø² provider"""
        provider_class = self.get_provider_class(slug)
        if not provider_class:
            raise ValueError(f"Provider '{slug}' not found")
        
        return provider_class(api_key=api_key, config=config or {})
    
    @staticmethod
    def get_available_models(slug: str, api_key: str, 
                            capability: str = None) -> List[dict]:
        """
        â­ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² API (Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB)
        Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ cache Ù…ÛŒØ´Ù† Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
        """
        from django.core.cache import cache
        
        # Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
        cache_key = f"available_models_{slug}_{capability}"
        cached = cache.get(cache_key)
        if cached:
            return cached
        
        # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ø§Ø³ provider
        registry = AIProviderRegistry()
        provider_class = registry.get_provider_class(slug)
        
        if not provider_class or not hasattr(provider_class, 'get_available_models'):
            return []
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² API
        try:
            models = provider_class.get_available_models(
                api_key=api_key,
                use_cache=True
            )
            
            # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ capability
            if capability:
                models = [m for m in models 
                         if registry._supports_capability(m, capability, slug)]
            
            # Ú©Ø´ Ú©Ø±Ø¯Ù† (6 Ø³Ø§Ø¹Øª)
            cache.set(cache_key, models, 6 * 60 * 60)
            return models
            
        except Exception:
            return []
    
    @staticmethod
    def _supports_capability(model: dict, capability: str, provider_slug: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø¯Ù„ Ø§Ø² capability Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡"""
        model_id = model.get('id', '').lower()
        
        # Ù‡Ø± provider Ø´ÛŒÙˆÙ‡ Ø®Ø§Øµ Ø®ÙˆØ¯Ø´ Ø±Ùˆ Ø¯Ø§Ø±Ù‡
        if provider_slug == 'huggingface':
            task = model.get('task', '').lower()
            capability_map = {
                'chat': ['text-generation'],
                'content': ['text-generation'],
                'image': ['text-to-image', 'image-to-image'],
                'audio': ['text-to-speech', 'automatic-speech-recognition']
            }
            return task in capability_map.get(capability, [])
        
        # Ø¨Ø±Ø§ÛŒ Ø¨Ù‚ÛŒÙ‡ØŒ Ø§Ø² Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        capability_keywords = {
            'image': ['dall-e', 'stable-diffusion', 'flux', 'midjourney', 'imagen'],
            'audio': ['tts', 'whisper', 'text-to-speech'],
            'chat': ['gpt', 'llama', 'gemini', 'claude', 'mistral'],
            'content': ['gpt', 'llama', 'gemini', 'claude', 'mistral']
        }
        
        keywords = capability_keywords.get(capability, [])
        return any(kw in model_id for kw in keywords)

# â­ Initialize ØªÙ†Ù‡Ø§ ÛŒÚ© Ø¨Ø§Ø±
_registry = AIProviderRegistry()

3ï¸âƒ£ View Ø¨Ø±Ø§ÛŒ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†
python# Backend/src/ai/views/ai_model_management_views.py

from rest_framework import viewsets, status
from rest_framework.decorators import action
from django.core.cache import cache

from src.ai.providers.registry import AIProviderRegistry
from src.ai.models import AIProvider, AIModel

class AIModelManagementViewSet(viewsets.ViewSet):
    """
    â­ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†
    
    Ø§ÛŒÙ† ViewSet:
    1. Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ùˆ real-time Ø§Ø² API Ù…ÛŒÚ¯ÛŒØ±Ù‡
    2. Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø±Ùˆ Ø¯Ø± DB Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
    3. ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± capability
    """
    
    @action(detail=False, methods=['get'], url_path='browse-models')
    def browse_models(self, request):
        """
        ğŸ“‹ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ available Ø§Ø² API
        
        Query Params:
        - provider: openrouter, huggingface, groq (required)
        - capability: chat, image, content, audio (required)
        
        Response:
        {
            "provider": "openrouter",
            "capability": "chat",
            "models": [
                {
                    "id": "google/gemini-2.0-flash",
                    "name": "Gemini 2.0 Flash",
                    "pricing": {...}
                },
                ...
            ],
            "total": 400,
            "selected_model": "google/gemini-2.0-flash"  # Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ
        }
        """
        provider_slug = request.query_params.get('provider')
        capability = request.query_params.get('capability')
        
        if not provider_slug or not capability:
            return APIResponse.error(
                message="Both 'provider' and 'capability' are required",
                status_code=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            # 1. Ú†Ú© Ú©Ø±Ø¯Ù† provider
            provider = AIProvider.objects.get(slug=provider_slug, is_active=True)
            
            # 2. Ø¯Ø±ÛŒØ§ÙØª API key
            api_key = provider.get_shared_api_key()
            if not api_key:
                return APIResponse.error(
                    message=f"No API key configured for {provider_slug}",
                    status_code=status.HTTP_400_BAD_REQUEST
                )
            
            # 3. Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² API (Ø¨Ø§ cache)
            registry = AIProviderRegistry()
            models = registry.get_available_models(
                slug=provider_slug,
                api_key=api_key,
                capability=capability
            )
            
            # 4. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÙØ¹Ù„ÛŒ
            selected_model = None
            try:
                active_model = AIModel.objects.get(
                    provider=provider,
                    capabilities__contains=capability,
                    is_active=True
                )
                selected_model = active_model.model_id
            except AIModel.DoesNotExist:
                pass
            
            return APIResponse.success(
                message=f"Found {len(models)} models for {provider_slug}/{capability}",
                data={
                    'provider': provider_slug,
                    'provider_name': provider.display_name,
                    'capability': capability,
                    'models': models,
                    'total': len(models),
                    'selected_model': selected_model
                }
            )
            
        except AIProvider.DoesNotExist:
            return APIResponse.error(
                message=f"Provider '{provider_slug}' not found or inactive",
                status_code=status.HTTP_404_NOT_FOUND
            )
        except Exception as e:
            return APIResponse.error(
                message=f"Error fetching models: {str(e)}",
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
    @action(detail=False, methods=['post'], url_path='select-model')
    def select_model(self, request):
        """
        âœ… Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB
        
        Body:
        {
            "provider": "openrouter",
            "capability": "chat",
            "model_id": "google/gemini-2.0-flash",
            "model_name": "Gemini 2.0 Flash"
        }
        
        Ø§ÛŒÙ† endpoint:
        1. Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ Ø±Ùˆ ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
        2. Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø±Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ (ÙÙ‚Ø· ÛŒÚ©ÛŒ!)
        3. Ú©Ø´ Ø±Ùˆ Ù¾Ø§Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù‡
        """
        provider_slug = request.data.get('provider')
        capability = request.data.get('capability')
        model_id = request.data.get('model_id')
        model_name = request.data.get('model_name')
        
        if not all([provider_slug, capability, model_id, model_name]):
            return APIResponse.error(
                message="All fields are required: provider, capability, model_id, model_name",
                status_code=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            provider = AIProvider.objects.get(slug=provider_slug, is_active=True)
            
            # âš ï¸ Ù…Ù‡Ù…: ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ù‡Ø± capability
            # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒØ´Ù† (Ø¯Ø± save())
            model, created = AIModel.objects.update_or_create(
                provider=provider,
                model_id=model_id,
                defaults={
                    'name': model_name,
                    'display_name': model_name,
                    'capabilities': [capability],
                    'is_active': True,
                }
            )
            
            # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ø´
            from src.ai.utils.cache import AICacheManager
            AICacheManager.invalidate_models()
            cache.delete(f"active_model_{provider_slug}_{capability}")
            
            return APIResponse.success(
                message=f"Model selected successfully",
                data={
                    'id': model.id,
                    'model_id': model.model_id,
                    'name': model.display_name,
                    'capability': capability,
                    'provider': provider_slug,
                    'is_active': model.is_active,
                    'created': created
                }
            )
            
        except AIProvider.DoesNotExist:
            return APIResponse.error(
                message=f"Provider '{provider_slug}' not found",
                status_code=status.HTTP_404_NOT_FOUND
            )
        except Exception as e:
            return APIResponse.error(
                message=f"Error selecting model: {str(e)}",
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
    @action(detail=False, methods=['get'], url_path='selected-models')
    def get_selected_models(self, request):
        """
        ğŸ“Œ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ (Ø¯Ø± DB)
        
        Ø§ÛŒÙ† ÙÙ‚Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ø±Ùˆ Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡
        Ù…Ø«Ù„Ø§Ù‹: 5-10 Ù…Ø¯Ù„ (ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± capability)
        """
        provider_slug = request.query_params.get('provider')
        capability = request.query_params.get('capability')
        
        queryset = AIModel.objects.filter(
            is_active=True,
            provider__is_active=True
        ).select_related('provider')
        
        if provider_slug:
            queryset = queryset.filter(provider__slug=provider_slug)
        
        if capability:
            queryset = queryset.filter(capabilities__contains=capability)
        
        from src.ai.serializers.ai_provider_serializer import AIModelListSerializer
        serializer = AIModelListSerializer(queryset, many=True)
        
        return APIResponse.success(
            message="Selected models retrieved",
            data=serializer.data
        )
    
    @action(detail=False, methods=['get'], url_path='providers')
    def get_providers(self, request):
        """
        ğŸ¢ Ù„ÛŒØ³Øª providerÙ‡Ø§ÛŒ available
        
        Ø§ÛŒÙ† Ù„ÛŒØ³Øª dynamic Ù‡Ø³Øª - Ø§Ú¯Ù‡ provider Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø´Ù‡ØŒ
        Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒØ´Ù‡
        """
        capability = request.query_params.get('capability')
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Registry (dynamic!)
        registry = AIProviderRegistry()
        all_providers = registry.get_all_providers()
        
        # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ DB
        db_providers = AIProvider.objects.filter(is_active=True)
        
        result = []
        for slug, provider_class in all_providers.items():
            try:
                db_provider = db_providers.get(slug=slug)
                
                # Ú†Ú© Ú©Ø±Ø¯Ù† capability
                if capability:
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ provider Ø§ÛŒÙ† capability Ø±Ùˆ Ø¯Ø§Ø±Ù‡
                    from src.ai.providers.capabilities import supports_feature
                    if not supports_feature(slug, capability):
                        continue
                
                result.append({
                    'slug': slug,
                    'name': db_provider.display_name,
                    'has_api_key': bool(db_provider.shared_api_key),
                    'is_active': db_provider.is_active
                })
            except AIProvider.DoesNotExist:
                continue
        
        return APIResponse.success(
            message=f"Found {len(result)} providers",
            data=result
        )

4ï¸âƒ£ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Chat View (Ù…Ø«Ø§Ù„)
python# Backend/src/ai/views/chat_views.py

from src.ai.providers.registry import AIProviderRegistry

class AIChatViewSet(viewsets.ViewSet):
    
    @action(detail=False, methods=['post'], url_path='send-message')
    def send_message(self, request):
        """
        ğŸ’¬ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ú†Øª
        
        Ø§Ø² Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ chat Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
        """
        message = request.data.get('message')
        
        try:
            # 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ø¨Ø±Ø§ÛŒ chat
            active_model = AIModel.objects.select_related('provider').get(
                capabilities__contains='chat',
                is_active=True,
                provider__is_active=True
            )
            
            # 2. Ø¯Ø±ÛŒØ§ÙØª API key
            provider = active_model.provider
            settings = AdminProviderSettings.objects.filter(
                admin=request.user,
                provider=provider,
                is_active=True
            ).first()
            
            if settings and settings.personal_api_key:
                api_key = settings.get_personal_api_key()
            else:
                api_key = provider.get_shared_api_key()
            
            # 3. Ø§ÛŒØ¬Ø§Ø¯ instance Ø§Ø² provider (Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ!)
            registry = AIProviderRegistry()
            provider_instance = registry.create_instance(
                slug=provider.slug,
                api_key=api_key,
                config={'model': active_model.model_id}
            )
            
            # 4. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² provider
            loop = asyncio.get_event_loop()
            reply = loop.run_until_complete(
                provider_instance.chat(
                    message=message,
                    conversation_history=[]
                )
            )
            
            return APIResponse.success(
                message="Message sent successfully",
                data={
                    'message': message,
                    'reply': reply,
                    'model': active_model.display_name,
                    'provider': provider.display_name
                }
            )
            
        except AIModel.DoesNotExist:
            return APIResponse.error(
                message="No active chat model found. Please select a model first.",
                status_code=status.HTTP_404_NOT_FOUND
            )
        except Exception as e:
            return APIResponse.error(
                message=f"Chat error: {str(e)}",
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
```

---

## ğŸ“ **Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:**
```
Backend/src/ai/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ai_provider.py          âœ… AIProvider + AIModel
â”‚
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ base.py                 âœ… BaseProvider
â”‚   â”œâ”€â”€ registry.py             â­ NEW - Auto-discovery
â”‚   â”œâ”€â”€ gemini.py               âœ… Existing
â”‚   â”œâ”€â”€ openai.py               âœ… Existing
â”‚   â”œâ”€â”€ openrouter.py           âœ… Existing
â”‚   â”œâ”€â”€ groq.py                 âœ… Existing
â”‚   â”œâ”€â”€ huggingface.py          âœ… Existing
â”‚   â””â”€â”€ deepseek.py             âœ… Existing
â”‚
â”œâ”€â”€ views/
â”‚   â”œâ”€â”€ ai_model_management_views.py  â­ NEW - Browse & Select
â”‚   â”œâ”€â”€ chat_views.py           ğŸ”„ Update - Use Registry
â”‚   â”œâ”€â”€ content_generation_views.py   ğŸ”„ Update - Use Registry
â”‚   â”œâ”€â”€ image_generation_views.py     ğŸ”„ Update - Use Registry
â”‚   â””â”€â”€ audio_generation_views.py     ğŸ”„ Update - Use Registry
â”‚
â””â”€â”€ urls.py                     ğŸ”„ Update routes

ğŸ”— APIÙ‡Ø§ÛŒ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†:
bash# 1ï¸âƒ£ Ù„ÛŒØ³Øª providerÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
GET /api/admin/ai-model-management/providers/?capability=chat
â†’ { data: [{slug: "openrouter", name: "OpenRouter", ...}] }

# 2ï¸âƒ£ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒÚ© provider (Ø§Ø² API - Ø¨Ø¯ÙˆÙ† DB!)
GET /api/admin/ai-model-management/browse-models/?provider=openrouter&capability=chat
â†’ { models: [400 models...], selected_model: "google/gemini-2.0-flash" }

# 3ï¸âƒ£ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ (Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB)
POST /api/admin/ai-model-management/select-model/
Body: {provider: "openrouter", capability: "chat", model_id: "...", model_name: "..."}
â†’ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± AIModel

# 4ï¸âƒ£ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ (Ø§Ø² DB)
GET /api/admin/ai-model-management/selected-models/
â†’ { data: [ÙÙ‚Ø· 5-10 Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡] }

# 5ï¸âƒ£ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Chat
POST /api/admin/ai-chat/send-message/
Body: {message: "hello"}
â†’ Ø§Ø² Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ chat Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
```

---

## âœ… **Ù…Ø²Ø§ÛŒØ§:**

| ÙˆÛŒÚ˜Ú¯ÛŒ | ÙˆØ¶Ø¹ÛŒØª |
|------|-------|
| **Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§** | âœ… Real-time Ø§Ø² API (Ú©Ø´ Ø´Ø¯Ù‡) |
| **Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DB** | âœ… ÙÙ‚Ø· Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ (5-10 Ø±Ú©ÙˆØ±Ø¯) |
| **Dynamic** | âœ… Provider Ø¬Ø¯ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡ |
| **Ø¨Ø¯ÙˆÙ† Import** | âœ… ÙÙ‚Ø· Ø¯Ø± Registry |
| **Ø³Ø±Ø¹Øª** | âœ… Cache (6 Ø³Ø§Ø¹Øª) |
| **ÙÙ‚Ø· ÛŒÚ© Ù…Ø¯Ù„ ÙØ¹Ø§Ù„** | âœ… Ø¯Ø± save() Ú†Ú© Ù…ÛŒØ´Ù‡ |

---

## ğŸš€ **ÙÙ„ÙˆÛŒ Ú©Ø§Ù…Ù„:**
```
1. Ø§Ø¯Ù…ÛŒÙ† Ù…ÛŒØ±Ù‡ Chat Section â†’ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
   â†“
2. GET /providers/?capability=chat
   â†’ Ù„ÛŒØ³Øª providerÙ‡Ø§ (openrouter, groq, ...)
   â†“
3. Ø§Ù†ØªØ®Ø§Ø¨ "openrouter"
   â†“
4. GET /browse-models/?provider=openrouter&capability=chat
   â†’ Ù„ÛŒØ³Øª 400 Ù…Ø¯Ù„ Ø§Ø² OpenRouter API (Ú©Ø´ Ø´Ø¯Ù‡)
   â†“
5. Ø§Ù†ØªØ®Ø§Ø¨ "Gemini 2.0 Flash"
   â†“
6. POST /select-model/
   â†’ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± AIModel (ÙÙ‚Ø· Ø§ÛŒÙ† ÛŒÚ©ÛŒ!)
   â†’ Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒØ´Ù‡
   â†“
7. Ø§Ø² Ø§ÛŒÙ† Ø¨Ù‡ Ø¨Ø¹Ø¯ Chat Ø§Ø² Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
   â†’ Ø¨Ø¯ÙˆÙ† import Ø¯Ø³ØªÛŒ! (Ø§Ø² Registry)

ğŸ“ Ø®Ù„Ø§ØµÙ‡:
âœ… Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§: Real-time Ø§Ø² API (Ø¨Ø¯ÙˆÙ† DB)
âœ… Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡: Ø¯Ø± DB (ÙÙ‚Ø· ÛŒÚ©ÛŒ)
âœ… Dynamic: Provider Ø¬Ø¯ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡
âœ… Ø¨Ø¯ÙˆÙ† Import: Ø§Ø² Registry Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
âœ… Ø³Ø±Ø¹Øª: Cache Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
